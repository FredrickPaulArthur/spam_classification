{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8350,
     "status": "ok",
     "timestamp": 1710951923796,
     "user": {
      "displayName": "Fredrick Paul A",
      "userId": "15424905174411628688"
     },
     "user_tz": -330
    },
    "id": "quFjYeKLGftc",
    "outputId": "3825f7e8-55f6-4f64-d927-a02f4ea108d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\iamfr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       Subject: enron methanol ; meter # : 988291\\r\\n...\n",
       "1       Subject: hpl nom for january 9 , 2001\\r\\n( see...\n",
       "2       Subject: neon retreat\\r\\nho ho ho , we ' re ar...\n",
       "3       Subject: photoshop , windows , office . cheap ...\n",
       "4       Subject: re : indian springs\\r\\nthis deal is t...\n",
       "                              ...                        \n",
       "5166    Subject: put the 10 on the ft\\r\\nthe transport...\n",
       "5167    Subject: 3 / 4 / 2000 and following noms\\r\\nhp...\n",
       "5168    Subject: calpine daily gas nomination\\r\\n>\\r\\n...\n",
       "5169    Subject: industrial worksheets for august 2000...\n",
       "5170    Subject: important online banking alert\\r\\ndea...\n",
       "Name: text, Length: 5171, dtype: object"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer   # Term Frequency - Inverse Document Frequency\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "data = pd.read_csv(\n",
    "    \"spam_ham_dataset.csv\",\n",
    "    #on_bad_lines=False,\n",
    "    engine=\"python\"     # ParserError: Error tokenizing data. C error: EOF inside string starting at row 1989\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.dropna()\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = df[\"label_num\"]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1710951923797,
     "user": {
      "displayName": "Fredrick Paul A",
      "userId": "15424905174411628688"
     },
     "user_tz": -330
    },
    "id": "PrXY4fCBwsJr",
    "outputId": "c3fe1255-9e76-4689-d7a5-ac0ab396cf83"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       subject: enron methanol ; meter # : 988291\\r\\n...\n",
       "1       subject: hpl nom for january 9 , 2001\\r\\n( see...\n",
       "2       subject: neon retreat\\r\\nho ho ho , we ' re ar...\n",
       "3       subject: photoshop , windows , office . cheap ...\n",
       "4       subject: re : indian springs\\r\\nthis deal is t...\n",
       "                              ...                        \n",
       "5166    subject: put the 10 on the ft\\r\\nthe transport...\n",
       "5167    subject: 3 / 4 / 2000 and following noms\\r\\nhp...\n",
       "5168    subject: calpine daily gas nomination\\r\\n>\\r\\n...\n",
       "5169    subject: industrial worksheets for august 2000...\n",
       "5170    subject: important online banking alert\\r\\ndea...\n",
       "Name: text, Length: 5171, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Lower\n",
    "X = X.str.lower()\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1710951923797,
     "user": {
      "displayName": "Fredrick Paul A",
      "userId": "15424905174411628688"
     },
     "user_tz": -330
    },
    "id": "Ma2t6DoZw7-g",
    "outputId": "465d9afd-95dd-463e-aea5-7f20a55e3c98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject  enron methanol   meter     988291  this is a follow up to the note i gave you on monday   4   3   00   preliminary  flow data provided by daren      please override pop   s daily volume   presently zero   to reflect daily  activity you can obtain from gas control    this change is needed asap for economics purposes  '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Remove special characters\n",
    "spl_chars_removed = []\n",
    "for sentence in X:\n",
    "  spl_chars_removed.append(re.sub('[^A-Za-z0-9+]', \" \", sentence))\n",
    "X = spl_chars_removed\n",
    "\n",
    "X[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 260395,
     "status": "ok",
     "timestamp": 1710952184173,
     "user": {
      "displayName": "Fredrick Paul A",
      "userId": "15424905174411628688"
     },
     "user_tz": -330
    },
    "id": "j0oDN3Uu--mP",
    "outputId": "3c16e373-aa03-43c8-a39c-c36f09539e8f"
   },
   "outputs": [],
   "source": [
    "# 4. Lemmatize with Remove stopwords\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "tokenized_emails = []\n",
    "for text in X:\n",
    "  doc = nlp(text)   # for each email\n",
    "  tokens = [token.lemma_ for token in doc if not (token.is_stop or token.is_space)]\n",
    "\n",
    "  tokenized_emails.append(\" \".join(tokens))\n",
    "\n",
    "X = tokenized_emails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 857,
     "status": "ok",
     "timestamp": 1710954731123,
     "user": {
      "displayName": "Fredrick Paul A",
      "userId": "15424905174411628688"
     },
     "user_tz": -330
    },
    "id": "wOvxKpiqyb2N",
    "outputId": "ce554319-c0ae-4531-ac9a-8774f1a08f25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'fred', 'let\"s']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp2 = spacy.blank('en')\n",
    "doc2 = nlp2('I am fred eat\\'s')\n",
    "\n",
    "vocab = [token.text for token in nlp('I am fred let\"s')]\n",
    "vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFLt3LgUeVIl"
   },
   "source": [
    "TF-IDF vectorizer takes the vocabulary into account and calculates the Word Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5494,
     "status": "ok",
     "timestamp": 1710952189662,
     "user": {
      "displayName": "Fredrick Paul A",
      "userId": "15424905174411628688"
     },
     "user_tz": -330
    },
    "id": "BcI1L729UpJT",
    "outputId": "86c47832-8f49-4eb3-9ac5-d68f50c924e1"
   },
   "outputs": [],
   "source": [
    "# 5. Vectorize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(X)    # vectorizer.transform(x) can be used for already fitted Vectorizer\n",
    "\n",
    "\n",
    "X_tfidf_array = X_tfidf.toarray()\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf_array, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val , y_train, y_val = train_test_split(X_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1710952189662,
     "user": {
      "displayName": "Fredrick Paul A",
      "userId": "15424905174411628688"
     },
     "user_tz": -330
    },
    "id": "ZD-P71jhW9u8",
    "outputId": "3e4cc17d-6ba6-4c58-f112-c6ada601a3c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4187, 45992), (4187,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape         # (5171, 46161)  - where 46161 is the size of the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 51525,
     "status": "ok",
     "timestamp": 1710952241171,
     "user": {
      "displayName": "Fredrick Paul A",
      "userId": "15424905174411628688"
     },
     "user_tz": -330
    },
    "id": "KtoS_JqEBGyI",
    "outputId": "a266a983-1a8d-43f4-b783-a63f50e0012d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "131/131 [==============================] - 6s 36ms/step - loss: 0.4020 - accuracy: 0.8264 - val_loss: 0.2053 - val_accuracy: 0.9657\n",
      "Epoch 2/10\n",
      "131/131 [==============================] - 4s 29ms/step - loss: 0.1282 - accuracy: 0.9890 - val_loss: 0.1026 - val_accuracy: 0.9893\n",
      "Epoch 3/10\n",
      "131/131 [==============================] - 4s 31ms/step - loss: 0.0546 - accuracy: 0.9976 - val_loss: 0.0686 - val_accuracy: 0.9914\n",
      "Epoch 4/10\n",
      "131/131 [==============================] - 4s 30ms/step - loss: 0.0293 - accuracy: 0.9986 - val_loss: 0.0535 - val_accuracy: 0.9914\n",
      "Epoch 5/10\n",
      "131/131 [==============================] - 4s 29ms/step - loss: 0.0179 - accuracy: 0.9998 - val_loss: 0.0450 - val_accuracy: 0.9914\n",
      "Epoch 6/10\n",
      "131/131 [==============================] - 4s 29ms/step - loss: 0.0119 - accuracy: 0.9998 - val_loss: 0.0400 - val_accuracy: 0.9914\n",
      "Epoch 7/10\n",
      "131/131 [==============================] - 4s 30ms/step - loss: 0.0084 - accuracy: 0.9998 - val_loss: 0.0364 - val_accuracy: 0.9914\n",
      "Epoch 8/10\n",
      "131/131 [==============================] - 4s 30ms/step - loss: 0.0062 - accuracy: 0.9998 - val_loss: 0.0342 - val_accuracy: 0.9914\n",
      "Epoch 9/10\n",
      "131/131 [==============================] - 4s 30ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.0323 - val_accuracy: 0.9914\n",
      "Epoch 10/10\n",
      "131/131 [==============================] - 4s 31ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0310 - val_accuracy: 0.9914\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(45992,)),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1141,
     "status": "ok",
     "timestamp": 1710955070909,
     "user": {
      "displayName": "Fredrick Paul A",
      "userId": "15424905174411628688"
     },
     "user_tz": -330
    },
    "id": "atIq867PvY2l",
    "outputId": "437a729b-5047-49d0-bbb8-99680ccdc319"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9846\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mZt1D42xiMA"
   },
   "source": [
    "### Model prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 388,
     "status": "ok",
     "timestamp": 1710955117269,
     "user": {
      "displayName": "Fredrick Paul A",
      "userId": "15424905174411628688"
     },
     "user_tz": -330
    },
    "id": "0ehFhL5JuUIs",
    "outputId": "194dba81-f9d4-46b8-e5e6-41ee91604a9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 111ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ham', 'spam', 'spam', 'ham', 'ham']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_predictions(model, X_predict):\n",
    "  y_preds = model.predict(X_predict).reshape((X_predict.shape[0], ))  # the rows - number of emails\n",
    "  preds_spam_ham = ['spam' if prob==1 else 'ham' for prob in np.round(y_preds)]\n",
    "\n",
    "  return preds_spam_ham\n",
    "\n",
    "\n",
    "test_emails = vectorizer.transform(\n",
    "  ['Dinner tonight in my house', 'free money lottery coupons now', 'youve won the lottery click the link', 'Breakfast today in John\\'s house', 'The principal asked us to leave']\n",
    ").toarray()\n",
    "\n",
    "model_predictions(model, test_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1175,
     "status": "ok",
     "timestamp": 1710953453684,
     "user": {
      "displayName": "Fredrick Paul A",
      "userId": "15424905174411628688"
     },
     "user_tz": -330
    },
    "id": "MqaJpju-vY_s",
    "outputId": "41aeb906-1692-4ffc-91ba-9e835bbdd5d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step\n",
      "['ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'spam', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'spam', 'spam', 'spam', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'spam', 'spam', 'spam', 'spam', 'spam', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'spam', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'spam', 'spam', 'spam', 'ham', 'spam', 'ham', 'spam', 'ham', 'spam', 'spam', 'ham', 'spam', 'spam', 'spam', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'spam', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'spam', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'spam', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'ham']\n"
     ]
    }
   ],
   "source": [
    "predictions = model_predictions(model, X_test)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxnKiw+7aFFxa87FyuycfM",
   "mount_file_id": "1g4mdcU9TD0VyH630Ofo-5qVTYJB80ade",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
